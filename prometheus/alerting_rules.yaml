alertmanagerFiles:
  alertmanager.yml:
    global:
      resolve_timeout: 1m
      slack_api_url: 'https://hooks.slack.com/services/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'

    receivers:
      - name: slack-notifications
        slack_configs:
         - channel: '#engineering'
           send_resolved: true
           icon_url: https://avatars3.githubusercontent.com/u/3380462
           title: |-
            [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }} for {{ .CommonLabels.job }}
            {{- if gt (len .CommonLabels) (len .GroupLabels) -}}
             {{" "}}(
             {{- with .CommonLabels.Remove .GroupLabels.Names }}
              {{- range $index, $label := .SortedPairs -}}
               {{ if $index }}, {{ end }}
               {{- $label.Name }}="{{ $label.Value -}}"
              {{- end }}
             {{- end -}}
             )
            {{- end }}
           text: >-
            {{ range .Alerts -}}
            *Alert:* {{ .Annotations.title }}{{ if .Labels.severity }} - `{{ .Labels.severity }}`{{ end }}
            
            *Description:* {{ .Annotations.description }}
            
            *Details:*
               {{ range .Labels.SortedPairs }} â€¢ *{{ .Name }}:* `{{ .Value }}` 
               {{ end }}
             {{ end }}

    route:
      group_wait: 10s
      group_interval: 5m
      receiver: slack-notifications
      repeat_interval: 3h
serverFiles:
    alerting_rules.yml:
        groups:
          - name: Instances
            rules:
              - alert: InstanceDown
                expr: up == 0
                for: 5m
                labels:
                  severity: page
                annotations:
                  description: '{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.'
                  summary: 'Instance {{ $labels.instance }} InstanceDown'
              - alert: HostOutOfMemory
                expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host out of memory (instance {{ $labels.instance }})
                  description: "Node memory is filling up (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostMemoryUnderMemoryPressure
                expr: rate(node_vmstat_pgmajfault[1m]) > 1000
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host memory under memory pressure (instance {{ $labels.instance }})
                  description: "The node is under heavy memory pressure. High rate of major page faults\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostUnusualNetworkThroughputIn
                expr: sum by (instance) (rate(node_network_receive_bytes_total[2m])) / 1024 / 1024 > 100
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: Host unusual network throughput in (instance {{ $labels.instance }})
                  description: "Host network interfaces are probably receiving too much data (> 100 MB/s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostUnusualNetworkThroughputOut
                expr: sum by (instance) (rate(node_network_transmit_bytes_total[2m])) / 1024 / 1024 > 100
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: Host unusual network throughput out (instance {{ $labels.instance }})
                  description: "Host network interfaces are probably sending too much data (> 100 MB/s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostUnusualDiskReadRate
                expr: sum by (instance) (rate(node_disk_read_bytes_total[2m])) / 1024 / 1024 > 50
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: Host unusual disk read rate (instance {{ $labels.instance }})
                  description: "Disk is probably reading too much data (> 50 MB/s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostUnusualDiskWriteRate
                expr: sum by (instance) (rate(node_disk_written_bytes_total[2m])) / 1024 / 1024 > 50
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host unusual disk write rate (instance {{ $labels.instance }})
                  description: "Disk is probably writing too much data (> 50 MB/s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              # Please add ignored mountpoints in node_exporter parameters like
              # "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|run)($|/)".
              # Same rule using "node_filesystem_free_bytes" will fire when disk fills for non-root users.
              - alert: HostOutOfDiskSpace
                expr: (node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) node_filesystem_readonly == 0
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host out of disk space (instance {{ $labels.instance }})
                  description: "Disk is almost full (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              # Please add ignored mountpoints in node_exporter parameters like
              # "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|run)($|/)".
              # Same rule using "node_filesystem_free_bytes" will fire when disk fills for non-root users.
              - alert: HostDiskWillFillIn24Hours
                expr: (node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs"}[1h], 24 * 3600) < 0 and ON (instance, device, mountpoint) node_filesystem_readonly == 0
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host disk will fill in 24 hours (instance {{ $labels.instance }})
                  description: "Filesystem is predicted to run out of space within the next 24 hours at current write rate\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostOutOfInodes
                expr: node_filesystem_files_free{mountpoint ="/rootfs"} / node_filesystem_files{mountpoint="/rootfs"} * 100 < 10 and ON (instance, device, mountpoint) node_filesystem_readonly{mountpoint="/rootfs"} == 0
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host out of inodes (instance {{ $labels.instance }})
                  description: "Disk is almost running out of available inodes (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostInodesWillFillIn24Hours
                expr: node_filesystem_files_free{mountpoint ="/rootfs"} / node_filesystem_files{mountpoint="/rootfs"} * 100 < 10 and predict_linear(node_filesystem_files_free{mountpoint="/rootfs"}[1h], 24 * 3600) < 0 and ON (instance, device, mountpoint) node_filesystem_readonly{mountpoint="/rootfs"} == 0
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host inodes will fill in 24 hours (instance {{ $labels.instance }})
                  description: "Filesystem is predicted to run out of inodes within the next 24 hours at current write rate\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostUnusualDiskReadLatency
                expr: rate(node_disk_read_time_seconds_total[1m]) / rate(node_disk_reads_completed_total[1m]) > 0.1 and rate(node_disk_reads_completed_total[1m]) > 0
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host unusual disk read latency (instance {{ $labels.instance }})
                  description: "Disk latency is growing (read operations > 100ms)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostUnusualDiskWriteLatency
                expr: rate(node_disk_write_time_seconds_total[1m]) / rate(node_disk_writes_completed_total[1m]) > 0.1 and rate(node_disk_writes_completed_total[1m]) > 0
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host unusual disk write latency (instance {{ $labels.instance }})
                  description: "Disk latency is growing (write operations > 100ms)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostHighCpuLoad
                expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[2m])) * 100) > 80
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: Host high CPU load (instance {{ $labels.instance }})
                  description: "CPU load is > 80%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostCpuStealNoisyNeighbor
                expr: avg by(instance) (rate(node_cpu_seconds_total{mode="steal"}[5m])) * 100 > 10
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: Host CPU steal noisy neighbor (instance {{ $labels.instance }})
                  description: "CPU steal is > 10%. A noisy neighbor is killing VM performances or a spot instance may be out of credit.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              # 1000 context switches is an arbitrary number.
              # Alert threshold depends on nature of application.
              # Please read: https://github.com/samber/awesome-prometheus-alerts/issues/58
              - alert: HostContextSwitching
                expr: (rate(node_context_switches_total[5m])) / (count without(cpu, mode) (node_cpu_seconds_total{mode="idle"})) > 1000
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: Host context switching (instance {{ $labels.instance }})
                  description: "Context switching is growing on node (> 1000 / s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostSwapIsFillingUp
                expr: (1 - (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes)) * 100 > 80
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host swap is filling up (instance {{ $labels.instance }})
                  description: "Swap is filling up (>80%)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostSystemdServiceCrashed
                expr: node_systemd_unit_state{state="failed"} == 1
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: Host systemd service crashed (instance {{ $labels.instance }})
                  description: "systemd service crashed\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostPhysicalComponentTooHot
                expr: node_hwmon_temp_celsius > 75
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: Host physical component too hot (instance {{ $labels.instance }})
                  description: "Physical hardware component too hot\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostNodeOvertemperatureAlarm
                expr: node_hwmon_temp_crit_alarm_celsius == 1
                for: 0m
                labels:
                  severity: critical
                annotations:
                  summary: Host node overtemperature alarm (instance {{ $labels.instance }})
                  description: "Physical node temperature alarm triggered\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostRaidArrayGotInactive
                expr: node_md_state{state="inactive"} > 0
                for: 0m
                labels:
                  severity: critical
                annotations:
                  summary: Host RAID array got inactive (instance {{ $labels.instance }})
                  description: "RAID array {{ $labels.device }} is in degraded state due to one or more disks failures. Number of spare drives is insufficient to fix issue automatically.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostRaidDiskFailure
                expr: node_md_disks{state="failed"} > 0
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host RAID disk failure (instance {{ $labels.instance }})
                  description: "At least one device in RAID array on {{ $labels.instance }} failed. Array {{ $labels.md_device }} needs attention and possibly a disk swap\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostKernelVersionDeviations
                expr: count(sum(label_replace(node_uname_info, "kernel", "$1", "release", "([0-9]+.[0-9]+.[0-9]+).*")) by (kernel)) > 1
                for: 6h
                labels:
                  severity: warning
                annotations:
                  summary: Host kernel version deviations (instance {{ $labels.instance }})
                  description: "Different kernel versions are running\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostOomKillDetected
                expr: increase(node_vmstat_oom_kill[1m]) > 0
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: Host OOM kill detected (instance {{ $labels.instance }})
                  description: "OOM kill detected\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostEdacCorrectableErrorsDetected
                expr: increase(node_edac_correctable_errors_total[1m]) > 0
                for: 0m
                labels:
                  severity: info
                annotations:
                  summary: Host EDAC Correctable Errors detected (instance {{ $labels.instance }})
                  description: "Host {{ $labels.instance }} has had {{ printf \"%.0f\" $value }} correctable memory errors reported by EDAC in the last 5 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostEdacUncorrectableErrorsDetected
                expr: node_edac_uncorrectable_errors_total > 0
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: Host EDAC Uncorrectable Errors detected (instance {{ $labels.instance }})
                  description: "Host {{ $labels.instance }} has had {{ printf \"%.0f\" $value }} uncorrectable memory errors reported by EDAC in the last 5 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostNetworkReceiveErrors
                expr: rate(node_network_receive_errs_total[2m]) / rate(node_network_receive_packets_total[2m]) > 0.01
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host Network Receive Errors (instance {{ $labels.instance }})
                  description: "Host {{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf \"%.0f\" $value }} receive errors in the last five minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostNetworkTransmitErrors
                expr: rate(node_network_transmit_errs_total[2m]) / rate(node_network_transmit_packets_total[2m]) > 0.01
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host Network Transmit Errors (instance {{ $labels.instance }})
                  description: "Host {{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf \"%.0f\" $value }} transmit errors in the last five minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostNetworkInterfaceSaturated
                expr: (rate(node_network_receive_bytes_total{device!~"^tap.*"}[1m]) + rate(node_network_transmit_bytes_total{device!~"^tap.*"}[1m])) / node_network_speed_bytes{device!~"^tap.*"} > 0.8
                for: 1m
                labels:
                  severity: warning
                annotations:
                  summary: Host Network Interface Saturated (instance {{ $labels.instance }})
                  description: "The network interface \"{{ $labels.interface }}\" on \"{{ $labels.instance }}\" is getting overloaded.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostConntrackLimit
                expr: node_nf_conntrack_entries / node_nf_conntrack_entries_limit > 0.8
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: Host conntrack limit (instance {{ $labels.instance }})
                  description: "The number of conntrack is approching limit\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostClockSkew
                expr: (node_timex_offset_seconds > 0.05 and deriv(node_timex_offset_seconds[5m]) >= 0) or (node_timex_offset_seconds < -0.05 and deriv(node_timex_offset_seconds[5m]) <= 0)
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host clock skew (instance {{ $labels.instance }})
                  description: "Clock skew detected. Clock is out of sync.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostClockNotSynchronising
                expr: min_over_time(node_timex_sync_status[1m]) == 0 and node_timex_maxerror_seconds >= 16
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host clock not synchronising (instance {{ $labels.instance }})
                  description: "Clock not synchronising.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
          - name: Kubernetes
            rules:
              - alert: KubernetesNodeReady
                expr: kube_node_status_condition{condition="Ready",status="true"} == 0
                for: 10m
                labels:
                  severity: critical
                annotations:
                  summary: Kubernetes Node ready (instance {{ $labels.instance }})
                  description: "Node {{ $labels.node }} has been unready for a long time\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesMemoryPressure
                expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
                for: 2m
                labels:
                  severity: critical
                annotations:
                  summary: Kubernetes memory pressure (instance {{ $labels.instance }})
                  description: "{{ $labels.node }} has MemoryPressure condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesDiskPressure
                expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
                for: 2m
                labels:
                  severity: critical
                annotations:
                  summary: Kubernetes disk pressure (instance {{ $labels.instance }})
                  description: "{{ $labels.node }} has DiskPressure condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesOutOfDisk
                expr: kube_node_status_condition{condition="OutOfDisk",status="true"} == 1
                for: 2m
                labels:
                  severity: critical
                annotations:
                  summary: Kubernetes out of disk (instance {{ $labels.instance }})
                  description: "{{ $labels.node }} has OutOfDisk condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesOutOfCapacity
                expr: sum by (node) ((kube_pod_status_phase{phase="Running"} == 1) + on(pod, namespace) group_left(node) (0 * kube_pod_info)) / sum(kube_node_status_allocatable_pods) by (node) * 100 > 90
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Kubernetes out of capacity (instance {{ $labels.instance }})
                  description: "{{ $labels.node }} is out of capacity\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesContainerOomKiller
                expr: (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}[10m]) == 1
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: Kubernetes container oom killer (instance {{ $labels.instance }})
                  description: "Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesJobFailed
                expr: kube_job_status_failed > 0
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: Kubernetes Job failed (instance {{ $labels.instance }})
                  description: "Job {{$labels.namespace}}/{{$labels.exported_job}} failed to complete\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesCronjobSuspended
                expr: kube_cronjob_spec_suspend != 0
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: Kubernetes CronJob suspended (instance {{ $labels.instance }})
                  description: "CronJob {{ $labels.namespace }}/{{ $labels.cronjob }} is suspended\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesPersistentvolumeclaimPending
                expr: kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Kubernetes PersistentVolumeClaim pending (instance {{ $labels.instance }})
                  description: "PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesVolumeOutOfDiskSpace
                expr: kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100 < 10
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Kubernetes Volume out of disk space (instance {{ $labels.instance }})
                  description: "Volume is almost full (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesVolumeFullInFourDays
                expr: predict_linear(kubelet_volume_stats_available_bytes[6h], 4 * 24 * 3600) < 0
                for: 0m
                labels:
                  severity: critical
                annotations:
                  summary: Kubernetes Volume full in four days (instance {{ $labels.instance }})
                  description: "{{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is expected to fill up within four days. Currently {{ $value | humanize }}% is available.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesPersistentvolumeError
                expr: kube_persistentvolume_status_phase{phase=~"Failed|Pending", job="kube-state-metrics"} > 0
                for: 0m
                labels:
                  severity: critical
                annotations:
                  summary: Kubernetes PersistentVolume error (instance {{ $labels.instance }})
                  description: "Persistent volume is in bad state\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesStatefulsetDown
                expr: (kube_statefulset_status_replicas_ready / kube_statefulset_status_replicas_current) != 1
                for: 1m
                labels:
                  severity: critical
                annotations:
                  summary: Kubernetes StatefulSet down (instance {{ $labels.instance }})
                  description: "A StatefulSet went down\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesHpaScalingAbility
                expr: kube_hpa_status_condition{status="false", condition="AbleToScale"} == 1
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Kubernetes HPA scaling ability (instance {{ $labels.instance }})
                  description: "Pod is unable to scale\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesHpaMetricAvailability
                expr: kube_hpa_status_condition{status="false", condition="ScalingActive"} == 1
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: Kubernetes HPA metric availability (instance {{ $labels.instance }})
                  description: "HPA is not able to collect metrics\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesHpaScaleCapability
                expr: kube_hpa_status_desired_replicas >= kube_hpa_spec_max_replicas
                for: 2m
                labels:
                  severity: info
                annotations:
                  summary: Kubernetes HPA scale capability (instance {{ $labels.instance }})
                  description: "The maximum number of desired Pods has been hit\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesPodNotHealthy
                expr: min_over_time(sum by (namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown|Failed"})[15m:1m]) > 0
                for: 0m
                labels:
                  severity: critical
                annotations:
                  summary: Kubernetes Pod not healthy (instance {{ $labels.instance }})
                  description: "Pod has been in a non-ready state for longer than 15 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesPodCrashLooping
                expr: increase(kube_pod_container_status_restarts_total[1m]) > 3
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Kubernetes pod crash looping (instance {{ $labels.instance }})
                  description: "Pod {{ $labels.pod }} is crash looping\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesReplicassetMismatch
                expr: kube_replicaset_spec_replicas != kube_replicaset_status_ready_replicas
                for: 10m
                labels:
                  severity: warning
                annotations:
                  summary: Kubernetes ReplicasSet mismatch (instance {{ $labels.instance }})
                  description: "Deployment Replicas mismatch\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesDeploymentReplicasMismatch
                expr: kube_deployment_spec_replicas != kube_deployment_status_replicas_available
                for: 10m
                labels:
                  severity: warning
                annotations:
                  summary: Kubernetes Deployment replicas mismatch (instance {{ $labels.instance }})
                  description: "Deployment Replicas mismatch\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesStatefulsetReplicasMismatch
                expr: kube_statefulset_status_replicas_ready != kube_statefulset_status_replicas
                for: 10m
                labels:
                  severity: warning
                annotations:
                  summary: Kubernetes StatefulSet replicas mismatch (instance {{ $labels.instance }})
                  description: "A StatefulSet does not match the expected number of replicas.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesDeploymentGenerationMismatch
                expr: kube_deployment_status_observed_generation != kube_deployment_metadata_generation
                for: 10m
                labels:
                  severity: critical
                annotations:
                  summary: Kubernetes Deployment generation mismatch (instance {{ $labels.instance }})
                  description: "A Deployment has failed but has not been rolled back.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesStatefulsetGenerationMismatch
                expr: kube_statefulset_status_observed_generation != kube_statefulset_metadata_generation
                for: 10m
                labels:
                  severity: critical
                annotations:
                  summary: Kubernetes StatefulSet generation mismatch (instance {{ $labels.instance }})
                  description: "A StatefulSet has failed but has not been rolled back.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesStatefulsetUpdateNotRolledOut
                expr: max without (revision) (kube_statefulset_status_current_revision unless kube_statefulset_status_update_revision) * (kube_statefulset_replicas != kube_statefulset_status_replicas_updated)
                for: 10m
                labels:
                  severity: warning
                annotations:
                  summary: Kubernetes StatefulSet update not rolled out (instance {{ $labels.instance }})
                  description: "StatefulSet update has not been rolled out.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesDaemonsetRolloutStuck
                expr: kube_daemonset_status_number_ready / kube_daemonset_status_desired_number_scheduled * 100 < 100 or kube_daemonset_status_desired_number_scheduled - kube_daemonset_status_current_number_scheduled > 0
                for: 10m
                labels:
                  severity: warning
                annotations:
                  summary: Kubernetes DaemonSet rollout stuck (instance {{ $labels.instance }})
                  description: "Some Pods of DaemonSet are not scheduled or not ready\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesDaemonsetMisscheduled
                expr: kube_daemonset_status_number_misscheduled > 0
                for: 1m
                labels:
                  severity: critical
                annotations:
                  summary: Kubernetes DaemonSet misscheduled (instance {{ $labels.instance }})
                  description: "Some DaemonSet Pods are running where they are not supposed to run\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesCronjobTooLong
                expr: time() - kube_cronjob_next_schedule_time > 3600
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: Kubernetes CronJob too long (instance {{ $labels.instance }})
                  description: "CronJob {{ $labels.namespace }}/{{ $labels.cronjob }} is taking more than 1h to complete.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesJobSlowCompletion
                expr: kube_job_spec_completions - kube_job_status_succeeded > 0
                for: 12h
                labels:
                  severity: critical
                annotations:
                  summary: Kubernetes job slow completion (instance {{ $labels.instance }})
                  description: "Kubernetes Job {{ $labels.namespace }}/{{ $labels.job_name }} did not complete in time.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesApiServerErrors
                expr: sum(rate(apiserver_request_count{job="apiserver",code=~"^(?:5..)$"}[1m])) / sum(rate(apiserver_request_count{job="apiserver"}[1m])) * 100 > 3
                for: 2m
                labels:
                  severity: critical
                annotations:
                  summary: Kubernetes API server errors (instance {{ $labels.instance }})
                  description: "Kubernetes API server is experiencing high error rate\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesApiClientErrors
                expr: (sum(rate(rest_client_requests_total{code=~"(4|5).."}[1m])) by (instance, job) / sum(rate(rest_client_requests_total[1m])) by (instance, job)) * 100 > 1
                for: 2m
                labels:
                  severity: critical
                annotations:
                  summary: Kubernetes API client errors (instance {{ $labels.instance }})
                  description: "Kubernetes API client is experiencing high error rate\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesClientCertificateExpiresNextWeek
                expr: apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 7*24*60*60
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: Kubernetes client certificate expires next week (instance {{ $labels.instance }})
                  description: "A client certificate used to authenticate to the apiserver is expiring next week.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesClientCertificateExpiresSoon
                expr: apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 24*60*60
                for: 0m
                labels:
                  severity: critical
                annotations:
                  summary: Kubernetes client certificate expires soon (instance {{ $labels.instance }})
                  description: "A client certificate used to authenticate to the apiserver is expiring in less than 24.0 hours.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: KubernetesApiServerLatency
                expr: histogram_quantile(0.99, sum(rate(apiserver_request_latencies_bucket{subresource!="log",verb!~"^(?:CONNECT|WATCHLIST|WATCH|PROXY)$"} [10m])) WITHOUT (instance, resource)) / 1e+06 > 1
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Kubernetes API server latency (instance {{ $labels.instance }})
                  description: "Kubernetes API server has a 99th percentile latency of {{ $value }} seconds for {{ $labels.verb }} {{ $labels.resource }}.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

